{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "sys.path.insert(0, '/Users/angela/src/private/bias-in-datasets/active_learning/src')\n",
    "import Evaluate\n",
    "from Speedup import get_percent_speedup\n",
    "from Plotter import format_plot_2ys\n",
    "\n",
    "OURSYSTEM = \"Selective-Backprop (Us)\"\n",
    "BASELINE = \"Baseline\"\n",
    "RANDOM = \"Random\"\n",
    "BASELINE_COLOR =\"#009e73\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineResult:\n",
    "    def __init__(self, line_type, epoch, num_backprop, num_skip, loss, time, acc):\n",
    "        self.line_type = line_type\n",
    "        self.epoch = epoch\n",
    "        self.num_backprop = num_backprop\n",
    "        self.num_skip = num_skip\n",
    "        self.loss = loss\n",
    "        self.time = time\n",
    "        self.acc = acc\n",
    "\n",
    "    @property\n",
    "    def is_train(self):\n",
    "        return self.line_type == \"train_debug\"\n",
    "\n",
    "    @property\n",
    "    def is_test(self):\n",
    "        return self.line_type == \"test_debug\"\n",
    "\n",
    "\n",
    "def parse_line_v1(line):\n",
    "    vals = line.split(',')\n",
    "    if \"train_debug\" in line:\n",
    "        epoch = int(vals[1])\n",
    "        num_backprop = int(vals[2])\n",
    "        loss = float(vals[4])\n",
    "        time = float(vals[5])\n",
    "        acc = float(vals[6])\n",
    "        line_type = \"train_debug\"\n",
    "    elif \"test_debug\" in line:\n",
    "        epoch = int(vals[1])\n",
    "        num_backprop = int(vals[2])\n",
    "        loss = float(vals[3])\n",
    "        acc = float(vals[4])\n",
    "        time = float(vals[5])\n",
    "        line_type = \"test_debug\"\n",
    "    else:\n",
    "        return None\n",
    "    return LineResult(line_type, epoch, num_backprop, loss, time, acc)\n",
    "\n",
    "\n",
    "def parse_line_v2(line):\n",
    "    vals = line.split(',')\n",
    "    if \"train_debug\" in line:\n",
    "        epoch = int(vals[1])\n",
    "        num_backprop = int(vals[2])\n",
    "        num_skipped = int(vals[3])\n",
    "        loss = float(vals[5])\n",
    "        time = float(vals[6])\n",
    "        acc = float(vals[7])\n",
    "        line_type = \"train_debug\"\n",
    "    elif \"test_debug\" in line:\n",
    "        epoch = int(vals[1])\n",
    "        num_backprop = int(vals[2])\n",
    "        num_skipped = int(vals[3])\n",
    "        loss = float(vals[4])\n",
    "        acc = float(vals[5])\n",
    "        time = float(vals[6])\n",
    "        line_type = \"test_debug\"\n",
    "    else:\n",
    "        return None\n",
    "    return LineResult(line_type, epoch, num_backprop, num_skipped, loss, time, acc)\n",
    "\n",
    "\n",
    "def parser_for(filename):\n",
    "    version = filename.split('_')[-1]\n",
    "    if version == \"v1\":\n",
    "        return parse_line_v1\n",
    "    if version == \"v2\":\n",
    "        return parse_line_v2\n",
    "    if version == \"v3\":\n",
    "        return parse_line_v2\n",
    "    else:\n",
    "        Exception(\"Version cannot be {}\".format(version))\n",
    "\n",
    "\n",
    "def parse_file(filename):\n",
    "    parser = parser_for(filename)\n",
    "    with open(filename) as f:\n",
    "        parsed = [parser(line)\n",
    "                  for line in f]\n",
    "    return ([d for d in parsed if d and d.is_train],\n",
    "            [d for d in parsed if d and d.is_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    MATCHER = (\"^(.*)_(.*)_(.*)_(.*)_(\\d+)_(\\d*\\.?\\d*)_(\\d*\\.?\\d*)(_trial\\d+)(_seed\\d+)?\")\n",
    "    def __init__(self, filename, experiment_name):\n",
    "        print(filename)\n",
    "\n",
    "        groups = self.matches(filename)\n",
    "        self.strategy = groups[0]\n",
    "        self.dataset = groups[1]\n",
    "        self.network = groups[2]\n",
    "        self.top_k = float(groups[3])\n",
    "        self.pool_size = int(groups[4])\n",
    "        self.lr = float(groups[5])\n",
    "        self.decay = groups[6]\n",
    "        self.seed = None\n",
    "        self.experiment_name = experiment_name\n",
    "        unparsed_trial = groups[7]\n",
    "        self.trial = int(unparsed_trial.strip(\"_trial\"))\n",
    "        if groups[8]:\n",
    "            unparsed_seed = groups[8]\n",
    "            self.seed = int(unparsed_seed.strip(\"_seed\"))\n",
    "            \n",
    "    @property\n",
    "    def label(self):\n",
    "        if self.strategy == \"topk\":\n",
    "            label = \"{}, {}, {}, top_{}/{}\".format(self.experiment_name,\n",
    "                                                      self.strategy,\n",
    "                                                      self.network,\n",
    "                                                      int(self.top_k),\n",
    "                                                      self.pool_size)\n",
    "        elif self.strategy == \"lowk\":\n",
    "            label = \"{}, {}, {}, lowest_{}/{}\".format(self.experiment_name,\n",
    "                                                      self.strategy,\n",
    "                                                      self.network,\n",
    "                                                      int(self.top_k),\n",
    "                                                      self.pool_size)\n",
    "        elif self.strategy == \"randomk\":\n",
    "            label = \"{}, {}, {}, random_{}/{}\".format(self.experiment_name,\n",
    "                                                      self.strategy,\n",
    "                                                      self.network,\n",
    "                                                      int(self.top_k),\n",
    "                                                      self.pool_size)\n",
    "        elif self.strategy == \"kath\":\n",
    "            label = \"{}, {}, {}, {}/{}\".format(self.experiment_name,\n",
    "                                                      self.strategy,\n",
    "                                                      self.network,\n",
    "                                                      int(self.top_k),\n",
    "                                                      self.pool_size)\n",
    "        elif self.strategy == \"sampling\" or self.strategy == \"deterministic\":\n",
    "            label = \"{}, {}, {}, Min: {}\".format(self.experiment_name,\n",
    "                                                   self.strategy,\n",
    "                                                   self.network,\n",
    "                                                   self.top_k) \n",
    "        elif self.strategy == \"baseline\":\n",
    "            label = \"{}, {}, {}\".format(self.experiment_name,\n",
    "                                                   self.strategy,\n",
    "                                                   self.network) \n",
    "        elif self.strategy == \"kuangliu\":\n",
    "            label = \"{}, original\".format(self.experiment_name) \n",
    "        elif self.strategy == \"debug\":\n",
    "            label = \"{}, debug\".format(self.experiment_name) \n",
    "\n",
    "        #if self.seed:\n",
    "        #    label += \", seed-{}\".format(self.seed)\n",
    "        #else:\n",
    "        #    label += \", trial-{}\".format(self.trial)\n",
    "        return label\n",
    "            \n",
    "    def matches(self, filename):\n",
    "        import re\n",
    "        return (re.match(Config.MATCHER, filename)).groups()\n",
    "    \n",
    "def write_file(plot_file_prefix, show=False):\n",
    "\n",
    "    plot_file = \"{}.pdf\".format(plot_file_prefix)\n",
    "    plt.savefig(plot_file)\n",
    "    \n",
    "    print(plot_file)\n",
    "    \n",
    "    plot_file = \"{}.png\".format(plot_file_prefix)\n",
    "    plt.savefig(plot_file, format=\"png\", dpi=1000)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()\n",
    "\n",
    "def format_plot(xlabel, ylabel, label_size=10, grid=False):\n",
    "    plt.tick_params(axis='y', which='major', labelsize=label_size * 1.4)\n",
    "    plt.tick_params(axis='y', which='minor', labelsize=label_size * 1.2)\n",
    "    plt.tick_params(axis='x', which='major', labelsize=label_size * 1.4)\n",
    "    plt.tick_params(axis='x', which='minor', labelsize=label_size * 1.2)\n",
    "\n",
    "    plt.xlabel(xlabel, fontsize=label_size * 1.6)\n",
    "    plt.ylabel(ylabel, fontsize=label_size * 1.6)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().xaxis.grid(grid)\n",
    "    plt.gca().yaxis.grid(grid)\n",
    "    \n",
    "    leg = plt.legend(loc=0, prop={'size': label_size * 1.1})\n",
    "    for legobj in leg.legendHandles:\n",
    "        legobj.set_linewidth(2.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot(xs_by_config,\n",
    "         ys_by_config,\n",
    "         xlabel, ylabel,\n",
    "         plot_dir,\n",
    "         smoothing=0,\n",
    "         lw=1,\n",
    "         ymin=None,\n",
    "         ymax=None,\n",
    "         xmax=None,\n",
    "         ymarker=None,\n",
    "         ylog=False,\n",
    "         annotate_accuracy=False):\n",
    "    local_xmax = - float(\"inf\")\n",
    "    local_ymax = - float(\"inf\")\n",
    "    for config, ys in sorted(ys_by_config.iteritems(), key=lambda x: x[0].top_k):\n",
    "        if len(ys) == 0:\n",
    "            print \"No elements for {} in {}\".format(config.label, ylabel)\n",
    "            continue\n",
    "            \n",
    "        xs = xs_by_config[config]\n",
    "\n",
    "        for i in range(smoothing):\n",
    "            xs = [(l+r) / 2. for l, r in zip(xs[:-1], xs[1:])]\n",
    "            ys = [(l+r) / 2. for l, r in zip(ys[:-1], ys[1:])]\n",
    "        \n",
    "        #TODO get label here\n",
    "        label = config.label\n",
    "        if annotate_accuracy:\n",
    "            label += \", Acc:{}\".format(max(ys))\n",
    "\n",
    "        if config.top_k == config.pool_size or config.top_k == 1:\n",
    "            plt.plot(xs, ys, label=label, linestyle=\"--\", linewidth=lw, alpha=0.7, zorder=0)\n",
    "        else:\n",
    "            plt.plot(xs, ys, label=label, linewidth=lw, alpha=0.9, zorder=0)\n",
    "\n",
    "        if max(xs) > local_xmax:\n",
    "            local_xmax = max(xs)\n",
    "        if max(ys) > local_ymax:\n",
    "            local_ymax = max(ys)\n",
    "        if xmax:\n",
    "            plt.xlim(0, xmax)\n",
    "        if ymin is not None:\n",
    "            if ymax is not None:\n",
    "                plt.ylim(ymin, ymax)\n",
    "            else:\n",
    "                plt.ylim(ymin, local_ymax)\n",
    "\n",
    "        \n",
    "        # Add visual marker where we achieve ymarker accuracy      \n",
    "        xmarker = Evaluate.find_first_x_at_y(xs, ys, ymarker)\n",
    "        if xmarker:\n",
    "            print(\"xmarker: \", xmarker)\n",
    "            plt.scatter([xmarker], [ymarker], marker=\"*\", s=50, color=\"black\", zorder=1)\n",
    "            \n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "    \n",
    "    if len(ys_by_config.keys()) > 0:\n",
    "        plot_prefix = \"{}/{}_{}_{}_lr{}\".format(plot_dir,\n",
    "                                             config.experiment_name,\n",
    "                                             xlabel,\n",
    "                                            ylabel,\n",
    "                                            config.lr)\n",
    "        if ylog:\n",
    "            plt.yscale(\"log\")\n",
    "        format_plot(xlabel, ylabel)\n",
    "        \n",
    "        plt.axhline(y=10, color='gray', linestyle=':', linewidth=0.2)\n",
    "        plt.axhline(y=15, color='gray', linestyle=':', linewidth=0.2)\n",
    "        plt.axhline(y=20, color='gray', linestyle=':', linewidth=0.2)\n",
    "        plt.axhline(y=30, color='gray', linestyle=':', linewidth=0.2)\n",
    "        plt.axhline(y=40, color='gray', linestyle=':', linewidth=0.2)\n",
    "        write_file(plot_prefix, show=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_instantaneous(l):\n",
    "    lcopy = l[:]\n",
    "    lcopy.insert(0, 0)        \n",
    "    pairs = zip(lcopy[::1], lcopy[1::1])\n",
    "    ilist = [j - i for i, j in pairs]\n",
    "    return ilist\n",
    "\n",
    "def smooth(l, constant):\n",
    "    for i in range(constant):\n",
    "        l = [(l+r) / 2. for l, r in zip(l[:-1], l[1:])]\n",
    "    return l\n",
    "            \n",
    "def plot_experiments(experiment_names,\n",
    "                     experiments_dir,\n",
    "                     plot_dir,\n",
    "                     lrs=None,\n",
    "                     nets=None,\n",
    "                     trials=None,\n",
    "                     sampling_mins=None,\n",
    "                     smoothing=0,\n",
    "                     xmax=None,\n",
    "                     ymin=None,\n",
    "                     ymax=None,\n",
    "                     ymarker=None):\n",
    "    \n",
    "    train_num_backprops_by_config = {}\n",
    "    test_num_backprops_by_config = {}\n",
    "    test_num_inferences_by_config = {}\n",
    "    train_losses_by_config = {}\n",
    "    test_losses_by_config = {}\n",
    "    test_errors_by_config = {}\n",
    "    train_accuracies_by_config = {}\n",
    "    test_accuracies_by_config = {}\n",
    "    train_accuracies_by_config = {}\n",
    "    ratio_backpropped_by_config_xs = {}\n",
    "    ratio_backpropped_by_config_ys = {}\n",
    "\n",
    "    for experiment_name in experiment_names:\n",
    "        experiment_dir = os.path.join(experiments_dir, experiment_name)\n",
    "        for filename in os.listdir(experiment_dir):\n",
    "            if filename == \".DS_Store\" or filename == \"pickles\" or filename == \"sha\":\n",
    "                continue\n",
    "                \n",
    "            print(filename)\n",
    "\n",
    "            filepath = os.path.join(experiment_dir, filename)\n",
    "            config = Config(filename, experiment_name)\n",
    "            train_lines, test_lines = parse_file(filepath)\n",
    "            \n",
    "            if lrs and config.lr not in lrs:\n",
    "                continue\n",
    "            if nets and config.network not in nets:\n",
    "                continue\n",
    "            if trials and config.trial not in trials:\n",
    "                continue\n",
    "            if sampling_mins and config.top_k not in sampling_mins:\n",
    "                continue\n",
    "\n",
    "            train_num_backprops = [l.num_backprop / 1000000. for l in train_lines]\n",
    "            test_num_backprops = [l.num_backprop / 1000000. for l in test_lines]\n",
    "            test_num_inferences = [(l.num_backprop + l.num_skip) / 1000000. for l in test_lines]\n",
    "            train_num_inferences = [(l.num_backprop + l.num_skip) / 1000000. for l in train_lines]\n",
    "\n",
    "            instantaneous_train_num_backprops = make_instantaneous(train_num_backprops)\n",
    "            instantaneous_train_num_inferences = make_instantaneous(train_num_inferences)\n",
    "\n",
    "            train_losses = [l.loss for l in train_lines]\n",
    "            test_losses = [l.loss for l in test_lines]\n",
    "            train_accuracies = [l.acc for l in train_lines]\n",
    "            test_accuracies = [l.acc for l in test_lines]\n",
    "            test_errors = [100-l.acc for l in test_lines]\n",
    "            \n",
    "            ratio_backpropped_ys = smooth([x / float(y) \\\n",
    "                                           for x, y in zip(instantaneous_train_num_backprops,\n",
    "                                                           instantaneous_train_num_inferences)\n",
    "                                           if y > 0], 10)\n",
    "            ratio_backpropped_xs = smooth([l.num_backprop / 1000000. \\\n",
    "                                           for l in train_lines \\\n",
    "                                           if (l.num_backprop + l.num_skip) > 0], 10)\n",
    "            \n",
    "            train_num_backprops_by_config[config] = train_num_backprops\n",
    "            test_num_backprops_by_config[config] = test_num_backprops\n",
    "            test_num_inferences_by_config[config] = test_num_inferences\n",
    "            train_losses_by_config[config] = train_losses\n",
    "            test_losses_by_config[config] = test_losses\n",
    "            train_accuracies_by_config[config] = train_accuracies\n",
    "            test_accuracies_by_config[config] = test_accuracies\n",
    "            test_errors_by_config[config] = test_errors\n",
    "            ratio_backpropped_by_config_xs[config] = ratio_backpropped_xs\n",
    "            ratio_backpropped_by_config_ys[config] = ratio_backpropped_ys\n",
    "\n",
    "\n",
    "    plot(ratio_backpropped_by_config_xs, ratio_backpropped_by_config_ys, \"Num Images Backpropped (millions)\", \"Ratio Backpropped\", plot_dir, smoothing, lw=0.8, ymin=0, xmax=xmax)\n",
    "    #plot(train_num_backprops_by_config, train_losses_by_config, \"Num Images Backpropped (millions)\", \"Training Loss\", plot_dir, smoothing, lw=1, xmax=xmax)\n",
    "    plot(test_num_backprops_by_config, test_accuracies_by_config, \"Num Images Backpropped (millions)\", \"Test Accuracy\", plot_dir, smoothing, lw=1, ymin=ymin, ymax=ymax, xmax=xmax, ymarker=ymarker, annotate_accuracy=True)\n",
    "    plot(test_num_backprops_by_config, test_errors_by_config, \"Num Images Backpropped (millions)\", \"Test Error\", plot_dir, smoothing, lw=1, ymin=ymin, ymax=ymax, xmax=xmax,  ymarker=ymarker, ylog=True)\n",
    "    plot(test_num_inferences_by_config, test_errors_by_config, \"Num Images Forward Propped (millions)\", \"Test Error\", plot_dir, smoothing, lw=1, ymin=ymin, ymax=ymax, xmax=xmax, ymarker=ymarker, ylog=True)\n",
    "    plot(test_num_backprops_by_config, test_losses_by_config, \"Num Images Backpropped (millions)\", \"Test Loss\", plot_dir, smoothing, lw=1, xmax=xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percent_speedup(plot_dir, title, nb0, nb1s, nf1s, labels, max_alpha):\n",
    "    plot_prefix = \"{}/{}\".format(plot_dir, title)\n",
    "    if nb0 is None:\n",
    "        print(\"Baseline has not reached target error\")\n",
    "    for nb1, nf1, label in zip(nb1s, nf1s, labels):\n",
    "        if nb1 is None:\n",
    "            continue\n",
    "        ys = []\n",
    "        alphas = range(1, max_alpha + 1)\n",
    "        for alpha in alphas:\n",
    "            y = get_percent_speedup(nb0, nb1, nf1, alpha)\n",
    "            ys.append(y)\n",
    "        plt.plot(alphas, ys, label=label)\n",
    "    plt.ylim(-100, 100)\n",
    "\n",
    "    format_plot(\"Ratio of Backwards to Forwards Pass Latency\", \"Percent Speedup\")\n",
    "    write_file(plot_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_final_error_tradeoff(plot_dir, errors, forwards, labels):\n",
    "    plot_prefix = \"{}/{}\".format(plot_dir, \"final-error-forwards\")\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(forwards, errors)\n",
    "    for i, txt in enumerate(labels):\n",
    "        ax.annotate(txt, (forwards[i], errors[i]))\n",
    "    format_plot(\"Total # Forwards (millions)\", \"Final Error\")\n",
    "    ax.set_xlim(left=0)\n",
    "    write_file(plot_prefix, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glue for plot_final_error_tradeoff and plot_percent_speedup\n",
    "\n",
    "def plot_wallclock(plot_dir, target_errors, experimental_names, baseline_name, experimental_labels, final_bp, max_alpha):\n",
    "    nb0s = {}\n",
    "    nb1s = {}\n",
    "    nf1s = {}\n",
    "\n",
    "    final_errors = []\n",
    "    final_nfs = []\n",
    "    final_labels = []\n",
    "\n",
    "    # Experimental\n",
    "    for experimental_name, experimental_label in zip(experimental_names, experimental_labels):\n",
    "        data = Evaluate.evaluate_file(experimental_name, target_errors, [final_bp])\n",
    "        for target_error in target_errors:\n",
    "            if target_error not in nb1s.keys():\n",
    "                nb1s[target_error] = []\n",
    "                nf1s[target_error] = []\n",
    "            nb1s[target_error].append(data[\"target_errors\"][target_error][\"num_backwards\"])\n",
    "            nf1s[target_error].append(data[\"target_errors\"][target_error][\"num_forwards\"])\n",
    "        final_error = data[\"target_backwards\"][final_bp][\"error\"]\n",
    "        if final_error:\n",
    "            final_errors.append(final_error)\n",
    "            final_labels.append(experimental_label)\n",
    "            final_nfs.append(data[\"target_backwards\"][final_bp][\"num_forwards\"])\n",
    "        \n",
    "    # Baseline\n",
    "    data = Evaluate.evaluate_file(baseline_name, target_errors, [final_bp])\n",
    "    for target_error in target_errors:\n",
    "        nb0s[target_error] = data[\"target_errors\"][target_error][\"num_backwards\"]\n",
    "    final_error = data[\"target_backwards\"][final_bp][\"error\"]\n",
    "    if final_error:\n",
    "        final_errors.append(final_error)\n",
    "        final_labels.append(\"Baseline\")\n",
    "        final_nfs.append(data[\"target_backwards\"][final_bp][\"num_forwards\"])\n",
    "    \n",
    "    # Plot speedup\n",
    "    for target_error in target_errors:\n",
    "        title = \"error{}\".format(target_error)\n",
    "        plot_percent_speedup(plot_dir, title, nb0s[target_error], nb1s[target_error], nf1s[target_error], experimental_labels, max_alpha)\n",
    "\n",
    "    # Plot final error\n",
    "    plot_final_error_tradeoff(plot_dir, final_errors, final_nfs, final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error: 7.35, Forwards: 51.0, Backwards: 7.315713\n",
      "Final error: 5.82, Forwards: 60.95, Backwards: 11.511554\n",
      "Final error: 6.53, Forwards: 62.0, Backwards: 9.922832\n",
      "Final error: 8.53, Forwards: 57.95, Backwards: 6.880206\n",
      "Final error: 21.27, Forwards: 0.8, Backwards: 0.8\n",
      "(4.626675, 29.2, 'gradual')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3302ab4d5135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mmax_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mfinal_bps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mplot_wallclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_filepaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_bps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b0f883676d4d>\u001b[0m in \u001b[0;36mplot_wallclock\u001b[0;34m(plot_dir, target_errors, experimental_names, baseline_name, experimental_labels, final_bp, max_alpha)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtarget_error\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"error{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mplot_percent_speedup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb0s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb1s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf1s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m# Plot final error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-51545e8610b3>\u001b[0m in \u001b[0;36mplot_percent_speedup\u001b[0;34m(plot_dir, title, nb0, nb1s, nf1s, labels, max_alpha)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_percent_speedup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/angela/src/private/bias-in-datasets/active_learning/src/Speedup.pyc\u001b[0m in \u001b[0;36mget_percent_speedup\u001b[0;34m(nb0, nb1, nf1, alpha)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mLf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mLb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mlatency_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnb0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnb0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mlatency_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnb1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlatency_original\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlatency_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlatency_original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# proportional + transformation functions\n",
    "\n",
    "\n",
    "plot_home_dir = \"../plots\"\n",
    "experiment_dir = \"../data/output/cifar10/\"\n",
    "\n",
    "plot_dir = \"{}/190404_gradual/\".format(plot_home_dir)\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "    \n",
    "experiment_names = [\"190404_gradual\", \"190404_gradual0.25\", \"190404_gradual0.5\", \"190404_gradual2\"]\n",
    "experimental_filepaths = []\n",
    "experimental_labels = []\n",
    "baseline_filepath = None\n",
    "target_errors = [10, 15, 20, 25, 30, 35]\n",
    "\n",
    "\n",
    "if False:\n",
    "    plot_experiments(experiment_names,\n",
    "                     experiment_dir,\n",
    "                     plot_dir,\n",
    "                     nets=[\"mobilenetv2\"],\n",
    "                     trials=[1])\n",
    "if True:\n",
    "    for experiment_name in experiment_names:\n",
    "        filedir = os.path.join(experiment_dir, experiment_name)\n",
    "        filepath = os.path.join(filedir, \"sampling_cifar10_mobilenetv2_0.1_128_0.0_0.0005_trial1_seed1337_v2\")\n",
    "        experimental_filepaths.append(filepath)\n",
    "        experimental_labels.append(experiment_name.split(\"_\")[-1])\n",
    "\n",
    "    experiment_name = \"190408_baseline_gradual\"\n",
    "    filepath = os.path.join(experiment_dir, experiment_name, \n",
    "                                \"sampling_cifar10_mobilenetv2_1_128_0.0_0.0005_trial1_seed1337_v2\")\n",
    "    baseline_filepath = filepath\n",
    "\n",
    "    max_alpha = 20\n",
    "    final_bps = 17\n",
    "    plot_wallclock(plot_dir, target_errors, experimental_filepaths, baseline_filepath, experimental_labels, final_bps, max_alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
